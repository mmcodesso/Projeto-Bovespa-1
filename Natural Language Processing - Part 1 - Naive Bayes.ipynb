{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the Data\n",
    "data = pd.read_pickle('./data/data_clean/Data.pik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['Corpus']\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word.lower() for word in nopunc.split() if word.lower() not in stopwords.words('portuguese')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [tivit, terceirização, processos, serviços, te...\n",
       "1    [laudo, avaliação, conforme, instrução, cvm, 3...\n",
       "2    [rec, 844, securitizadora, créditos, imobiliár...\n",
       "3    [página, é, parte, integrante, ata, assembleia...\n",
       "4    [1, tec, toy, sa, companhia, aberta, cnpjmf, n...\n",
       "Name: Corpus, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure its working\n",
    "data['Corpus'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./variables/vectorizer/corpus_tidy.pik']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a corpus tidy to future. it will take about 1 hour to run\n",
    "corpus_tidy = data['Corpus'].apply(text_process)\n",
    "#Saving corpus_tidy  to future using\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(corpus_tidy, './variables/vectorizer/corpus_tidy.pik') \n",
    "\n",
    "CorpusTidy = pd.DataFrame(corpus_tidy)\n",
    "data['Corpus_tidy'] = CorpusTidy\n",
    "data.to_pickle('./data/data_clean/Data_Tidy.pik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "initime = time.time()\n",
    "\n",
    "# Might take awhile...\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(data['Corpus'])\n",
    "\n",
    "fimtime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407680\n",
      "Total Time:  81.23165499766668 minutes\n"
     ]
    }
   ],
   "source": [
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))\n",
    "\n",
    "#Print total time to create the vectorizer\n",
    "totaltime = (fimtime-initime) / 60\n",
    "print (\"Total Time: \", totaltime, \"minutes\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time:  89.77143399715423 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the clock\n",
    "initime = time.time()\n",
    "\n",
    "#Creates a bow corpus \n",
    "corpus_bow = bow_transformer.transform(data['Corpus'])\n",
    "\n",
    "#Print total time to create bow corpus\n",
    "fimtime = time.time()\n",
    "totaltime = (fimtime-initime) / 60\n",
    "print (\"Total Time: \", totaltime, \"minutes\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (6837, 407680)\n",
      "Amount of Non-Zero occurences:  3753943\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', corpus_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', corpus_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./variables/vectorizer/corpus_bow.pik']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving corpus_bow and bow_transformer to future using\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(bow_transformer, './variables/vectorizer/bow_transformer.pik') \n",
    "joblib.dump(corpus_bow, './variables/vectorizer/corpus_bow.pik') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6837, 407680)\n",
      "Total Time:  0.012891169389088948 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#start the clock\n",
    "initime = time.time()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(corpus_bow)\n",
    "corpus_tfidf = tfidf_transformer.transform(corpus_bow)\n",
    "\n",
    "print(corpus_tfidf.shape)\n",
    "\n",
    "#Print total time to create TF-IDF corpus\n",
    "fimtime = time.time()\n",
    "totaltime = (fimtime-initime) / 60\n",
    "print (\"Total Time: \", totaltime, \"minutes\" ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a BOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(corpus_bow, y, test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bow_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bow_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "        Cancelamento de Registro       0.46      0.11      0.17        56\n",
      "              Controle Acionario       0.40      0.07      0.12        27\n",
      "          Direito de Preferencia       0.58      0.11      0.18        65\n",
      "                       Dividendo       0.90      0.96      0.93       783\n",
      "                  Oferta Publica       0.72      0.77      0.75       190\n",
      "Pedido de Recuperação Judicial       0.95      0.51      0.67        72\n",
      "                    Subscrição       0.59      0.89      0.71       175\n",
      "\n",
      "                     avg / total       0.80      0.81      0.78      1368\n",
      "\n",
      "[[  6   0   0  17  22   0  11]\n",
      " [  0   2   1   9   9   2   4]\n",
      " [  0   0   7  12   4   0  42]\n",
      " [  3   2   1 749   3   0  25]\n",
      " [  4   0   2  17 147   0  20]\n",
      " [  0   0   1  14  12  37   8]\n",
      " [  0   1   0  12   6   0 156]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print (classification_report(y_test, y_pred))\n",
    "print (confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/bow_model_v1.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(bow_model, './model/bow_model_v1.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(corpus_tfidf, y, test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bow_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bow_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "        Cancelamento de Registro       0.00      0.00      0.00        56\n",
      "              Controle Acionario       0.00      0.00      0.00        27\n",
      "          Direito de Preferencia       0.00      0.00      0.00        65\n",
      "                       Dividendo       0.58      1.00      0.74       783\n",
      "                  Oferta Publica       0.93      0.07      0.13       190\n",
      "Pedido de Recuperação Judicial       0.00      0.00      0.00        72\n",
      "                    Subscrição       0.91      0.06      0.11       175\n",
      "\n",
      "                     avg / total       0.58      0.59      0.45      1368\n",
      "\n",
      "[[  0   0   0  55   1   0   0]\n",
      " [  0   0   0  27   0   0   0]\n",
      " [  0   0   0  64   0   0   1]\n",
      " [  0   0   0 783   0   0   0]\n",
      " [  0   0   0 177  13   0   0]\n",
      " [  0   0   0  72   0   0   0]\n",
      " [  0   0   0 165   0   0  10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriciomellocodesso/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print (classification_report(y_test, y_pred))\n",
    "print (confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is possible to notice that TF-IDF don't work for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Grid Search with Cross validation to bow model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'alpha' : (1, 1e-2,1e-3,1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_bow_model = GridSearchCV(MultinomialNB(), parameters, n_jobs=-1,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': (1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07, 1e-08, 1e-09, 1e-10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bow_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84073870908758452"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bow_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1e-06\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_bow_model.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gs_bow_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "        Cancelamento de Registro       0.36      0.50      0.42        56\n",
      "              Controle Acionario       0.58      0.26      0.36        27\n",
      "          Direito de Preferencia       0.61      0.42      0.50        65\n",
      "                       Dividendo       0.94      0.95      0.95       783\n",
      "                  Oferta Publica       0.79      0.71      0.75       190\n",
      "Pedido de Recuperação Judicial       0.97      0.79      0.87        72\n",
      "                    Subscrição       0.71      0.85      0.77       175\n",
      "\n",
      "                     avg / total       0.84      0.84      0.84      1368\n",
      "\n",
      "[[ 28   1   1   8  14   0   4]\n",
      " [  2   7   1   6   7   1   3]\n",
      " [  0   0  27   7   3   1  27]\n",
      " [ 19   2   1 747   4   0  10]\n",
      " [ 26   1   4  12 135   0  12]\n",
      " [  1   0   1   7   3  57   3]\n",
      " [  2   1   9  10   5   0 148]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print (classification_report(y_test, y_pred))\n",
    "print (confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
